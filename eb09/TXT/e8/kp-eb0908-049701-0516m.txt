+====================================================================+
 ENCYCLOPEDIA BRITANNICA, NINTH EDITION: A MACHINE-READABLE TEXT
 TRANSCRIPTION (v1.1), The Nineteenth-Century Knowledge Project, 2025
 nckp@temple.edu, https://tu-plogan.github.io/.

 License: CC-BY-4.0, https://creativecommons.org/licenses/by/4.0/.

 Source: Encyclopaedia Britannica: A Dictionary of Arts, Sciences,
 and General Literature. 9th ed., 25 vols. NY: Charles Scribner's
 Sons, 1875-1889. (Authorized edition.) Image scans: Internet Archive.

 This entry: 9th edition, volume 8, page 497 [9:8:497]
+====================================================================+


EQUATION. The present article includes Determinant and Theory of Equations; and it may be proper to explain the relation to each other of the two subjects. Theory of Equations is used in its ordinary conventional sense to denote the theory of a single equation of any order in one unknown quantity; that is, it does not include the theory of a system or systems of equations of any order between any number of unknown quantities. Such systems occur very frequently in analytical geometry and other parts of mathematics, but they are hardly as yet the subject-matter of a distinct theory; and even Elimination, the transition-process for passing fιom a system of any number of equations involving the same number of unknown quantities to a single equation in one unknown quantity, hardly belongs to the Theory of Equations in the above restricted sense. But there is one case of a system of equations which precedes the Theory of Equations, and indeed presents itself at the outset of algebra, that of a system of simple (or linear) equations. Such a system gives rise to the function called a Determinant, and it is by means of these functions that the solution of the equations is effected. We have thus the subject Determinant as nearly equivalent to (but somewhat more extensive than) that of a system of linear equations; and we have the other subject, Theory of Equations, used in the restricted sense above referred to, and as not including Elimination.

Determinant.

1. A sketch of the history of determinants is given under Algebra; it thereby appears that the algebraical function called a determinant presents itself in the solution of a system of simple equations, and we have herein a natural source of the theory. Thus, considering the equations ax + by + cz = d, a' x + b' y + d z = d', a"x + b"y + d'z = tZ", and proceeding to solve them by the so-called method of cross multiplication, we multiply the equations by factors selected in such a manner that upon adding the results the whole coefficient of y becomes = 0, and the whole coefficient of z becomes = 0; the factors in question are δ'c" - δ"c', b"c-bc, be - b'c (values which, as at once seen, have the desired property); we thus obtain an equation which contains on the left-hand side only a multiple of x, and on the right-hand side a constant term; the coefficient of x has the value

α(δ'c" - i·V) + a ∖ b"c - be") + a ’ (bc ’ - b’e), and this function, represented in the form fι , b , e; , α', b', c'! a", b", e" I

is said to be a determinant; or, the number of elements being 3 2 , it is called a determinant of the third order. It is to be'noticed that the resulting equation is a , b , c 1 x= ∖ d,b,c , α', b ’, c' d ’ , b ’ , c' I

a", δ", c" i I d", b", c" I where the expression on the right-hand side is the like function with d, d', d" in place of a, a, a" respectively, and is of course also a determinant. Moreover, the functions b , d' - b''d, b"c — be", bd - Pc used in the process are themselves the determinants of the second order

I b', c' I , I b", c'' I , I b, e I .

I b", e" ∖ i b, e i I b', e' i

We have herein the suggestion of the rule for the derivation of the determinants of the orders 1, 2, 3, 4, <fcc., each from the preceding one, viz., we have

∣ α l =α, ia,δ∣ =α[δ'∣ -α'jδ∣,

α', Z>'∣

∣α,δ,c∣ -αb',d ∖ + α'ιδ", c"l + α"ιδ,c∣,

!α',δ',c' ⅛'',c"! ⅛,c∣ ∣δ',c'l

;a", b", c" ∖ a ,b ,c ,d -a ∖ b ’ ,d,d ’ ∖ -a f ∖ b",d',d" +a" ∖ d",cl",d"' i -a'"b,c,d ∖ , a! ,b' ,c ’ ,d' ∖ b'' ,d' ,d" ∖ ∖ bl",d' , ,d''' ∖ ∣δ ,c ,d ∣ b' f d' a" ,b" ,c" ,d" ∖ b"' t <'",d'" ∖ ∖ b ,c ,d ∖ ∖ df,d' ∖ ti'f ’ ,d" ∖ a''' ,b'" f" ,d'" and so on, the terms being all + for a determinant of an odd order, but alternately + and - for a determinant of an even order.

2. It is easy, by induction, to arrive at the general results :—

A determinant of the order n is the sum of the 1.2.3...n products which can be formed with n elements out of n 2 elements arranged in the form of a square, no two of the n elements being in the same line or in the same column, and each such product having the coefficient ± unity.

The products in question may be obtained by permuting in every possible manner the columns (or the lines) of the determinant, and then taking for the factors the n elements in the dexter diagonal. And we thence derive the rule for the signs, viz., considering the primitive arrangement of the columns as positive, then an arrangement obtained therefrom by a single interchange (inversion, or derangement) of two columns is regarded as negative; and so in general an arrangement is positive or negative according as it is derived from the primitive arrangement by an even or an odd number of interchanges. [This implies the [9:8:498] theorem that a given arrangement can be derived from the primitive arrangement only by an odd number, or else only by an even number of interchanges,—a theorem the verification of which may be easily obtained from the theorem (in fact a particular case of the general one), an arrangement can be derived from itself only by an even number of interchanges.] And this being so, each product has the sign belonging to the corresponding arrangement of the columns; in particular, a determinant contains with the sign + the product of the elements in its dexter diagonal. It is to be observed that the rule gives as many positive as negative arrangements, the number of each being = ⅛L2...n,

The rule of signs may be expressed in a different form. Giving to the columns in the primitive arrangement the numbers 1, 2, 3...n, to obtain the sign belonging to any other arrangement we take, as often as a lower number succeeds a higher one, the sign -, and, compounding together all these minus signs, obtain the proper sign, + or - as the case may be.

Thus, for three columns, it appears by either rule tnat 123, 231, 312 are positive; 213, 321, 213 are negative; and the developed expression of the foregoing determinant of the third order is .

= ab'c" - ab"d + a'b"c - aibd' + a"bc' - a"b'c.

3. It further appears that a determinant is a linear function^[1. The expression, a linear function, is here used in its narrowest sense, a linear function without constant term; what is meant is, that the determinant is in regard to the elements a, a', a", . . of any column or line thereof, a function of the form Aα +A'α'+A"α" + . . . , without any term independent of a, a', a". . . ] of the elements of each column thereof, and also a linear function of the elements of each line thereof; moreover, that the determinant retains the same value, only its sign being altered, when any two columns are interchanged, or when any two lines are interchanged; more generally, when the columns are permuted in any manner, or when the lines are permuted in any manner, the determinant retains its original value, with the sign + or — according as the new arrangement (considered as derived from the primitive arrangement) is positive or negative according to the foregoing rule of signs. It at once follows that, if two columns are identical, or if two lines are identical, the value of the determinant is = 0. It may be added, that if the lines are converted into columns, and the columns into lines, in such a way as to leave the dexter diagonal unaltered, the value of the determinant is unaltered; the determinant is in this case said to be transposed.

4. By what precedes it appears that there exists a function of the n 2 elements, linear as regards the terms of each column (or say, for shortness, linear as to each column), and such that only the sign is altered when any two columns are interchanged; these properties completely determine the function, except as to a common factor which may multiply all the terms. If, to get rid of this arbitrary common factor, we assume that the product of the elements in the dexter diagonal has the coefficient + 1, we have a complete definition of the determinant, and it is interesting to show how from these properties, assumed for the definition of the determinant, it at once appears that the determinant is a function serving for the solution of a system of linear equations. Observe that the properties show at once that if any columnis =0 (that is, if the elements in the column are each =0), then the determinant is =0; and further, that if any two colurnus are identical, then the determinant is — 0.

5. Reverting to the system of linear equations written down at the beginning of this article, consider the determinant ax+by+cz-d ,b,c; a' x + b' y + c' z - d!, b', c' a"x + b"y + d ’ z -d", b", d' it appears that this is =« a , b , c ∣ + y b , b , c +z c , b , c - d , b , c , a' , b', c' i b', b' , c' c' , b' , c' d', b' , c'

a", b", c" ∖ b", b", c" c", b", c" d", b" , c" viz., the second and third terms each vanishing, it is =« a , b , c - ∖ d,b,c . a! , b', c' ∖ d', b' , c'

a", b", c" I d", b", d'

But if the linear equations hold good, then the first column of the original determinant is = 0, and therefore the determinant itself is = 0; that is, the linear equations give xi a , b , c - ∖ d,b,c =0;

α', b' , c' ∖ d' , b', c'

I a", ό", c" I d", à", c" which is the result obtained above.

We might in a similar way find the values of y and z, but there is a more symmetrical process. Join to the original equations the new equation

<w + 3y + γz=δ; a like process shows that, the equations being satisfied, we have « , ß , 7, δ =0; a , b , c , d a' , b' , c' , d' a", b", d', rf" or, as this may be written,

α,3>7 — δ a , b ,c =0; a b c , d a', b', c' a' b' c' , d' a", b", c" a" b" d', c?"

which, considering δ as standing herein for its value αx + ∕Sy + γz, is a consequence of the original equations only: we have thus an expression for ax + βy + yz, an arbitrary linear function of the unknown quantities x, y i z; and by comparing the coefficients of α, β, γ on the two sides respectively, we have the values of x,y,z^, in fact, these quantities, each multiplied by a , b , c; ,

α' , i>' , c'∣ a", b", c" ∖ are in the first instance obtained in the forms 1 > I 1 i »; 1 ; a , b , c , d a , b , c , d ∖ ι a , b , c , d a', b' , c', d' ∖ a', b', c', d' j a', b', d , d' a!', b", d', rf" I a", b", d', d"> ∣ a", b", d', d" but these are ∖ b,c,d ∖ ,-~ c , d , ct , d a , b , ∖ b', c', d' ∖ d , d', a' d' u', b'

I b", d', d" ∖ c", d", a!' d" a", b" or, what is the same thing, —— b , c , d [ , ∣ c , a , d , u , b , d I

b', c', d' I ∖ d , a', d' a' b', d' b",d',d" ∖ ∖ d',a",d" a" V',d" ∖ respectively.

6. Multiplication of two determinants of the same order. —The theorem is obtained very easily from the last preceding definition of a determinant. It is most simply expressed thus—

(a ,a',α"),(g,3',3"), (7,7',7")

(tt , b , C ) ,, ,, ,, = 9 ^, 9 ' α r 9 ^ f 9 f ∖ 9 (a' , b' ,d ) „ „ „ a! , b' , c' a , β' , 7'

(α",⅛",e")∣ a",δ",c" a", β", 7 " ∣ where the expression on the left side stands for a determinant, the terms of the first line being (a, b, c)(a, a', a"), that is, a a + ba + ca", (a, b, c)(β, β', β"), that is, aβ + bβ' + cβ", (a, b, c)(γ, γ', γ"), that is ay + by' + cγ"; and similarly the [9:8:499] terms in the second and third lines are the like functions with (α', b', c') and (α", δ", c") respectively.

There is an apparently arbitrary transposition of lines and columns; the result would hold good if on the lefthand side we had written (a, β, γ), (a', β' γ'), (a", β'j f'), or what is the same thing, if on the right-hand side we had transposed the second determinant; and either of these changes would, it might be thought, increase the elegance of the form, but, for a reason which need not be explained,^[2. The reason is the connexion with the corresponding theorem for the multiplication of two matrices. ] the form actually adopted is the preferable one.

To indicate the method of proof, observe that the determinant on the left-hand side, qua linear function of its columns, may be broken up into a sum of (3 3 = ) 27 determinants, each of which is either of some such form as ± αβf a , a , b I , a', a! , ⅛' a", a", i>"∣

where the term aβf is not a term of the αβγ-determinant, and its coefficient (as a determinant with two identical columns) vanishes ; or else it is of a form such as ± aβ'γ"i a , b , c i , α', δ' , c' I a", b", c"∣

that is, every term which does not vanish contains as a factor the αδodeterminant last written down; the sum of all other factors ± α β'f' is the aβγ- determinant of the formula; and the final result then is, that the determinant on the left-hand side is equal to the product on the right-hand side of the formula.

7. Decomposition of a determinant into complementary determinants.— Consider, for simplicity, a determinant of the fifth order, 5 = 2 + 3, and let the top two lines be α , b , e , d , e a' , b' , c' , d' , β'

then, if we consider how these elements enter into the determinant, it is at once seen that they enter only through ∣tz δ I

’ , &c., which a', ο' I ’ ’

can be formed by selecting any two columns at pleasure. Moreover, representing the remaining three lines by a" , δ" , c" , d" , c" α''', δ'" , c'", d'" , e" ’ a"", b"", c"", d"", e"" it is further seen that the factor which multiplies the determinant formed with any two columns of the first set is the determinant of the third order formed with the complementary three columns of the second set; and it thus appears that the determinant of the fifth order is a sum of all the products of the form

± I a, b I c" , d" ,e" I , I α', b' I e'", d'", e'" d'", d"", e"" I

the sign ± being in each case such that the sign of the term ± al>'. c'<T"d'" obtained from the diagonal elements of the component determinants may be the actual sign of this term in the determinant of the fifth order; for the product written down the sign is obviously + .

Observe that for a determinant of the n th order, taking the decomposition to be 1 + (n - 1 ), we fall back upon the equations given at the commencement, in order to show the genesis of a determinant.

∣tx 6 I

’ formed out of the elements of α, ο I

the original determinant, by selecting the linee and columns at pleasure, is termed a minor of the original determinant; and when the number of lines and columns.

or order of the determinant, is 72 — 1, then such determinant is called a first minor; the number of the first minors is = n ^[3. The coefficients were selected so that the roots might he nearly 1, 2, 3. ], the first minors, in fact, corresponding to the several elements of the determinant—that is, the coefficient therein of any term whatever is the corresponding first minor. The first minors, each divided by the determinant itself, form a system of elements inverse to the elements of the determinant.

A determinant is symmetrical when every two elements symmetrically situated in regard to the dexter diagonal are equal to each other; if they are equal and opposite (that is, if the sum of the two elements be =0), this relation not extending to the diagonal elements themselves, which remain arbitrary, then the determinant is shew; but if the relation does extend to the diagonal terms (that is, if these are each = 0), then the determinant is skew symmetrical; thus the determinants ∖ α , h , g ; a , v , — μ I; I 0, v , — μ ∖ h,l> ff -V , b , λl I - V , 0, λ

• 9 ,f > c y∙ > ~ h > c 1 I P∙ > - λ , 0

are respectively symmetrical, skew, and skew symmetrical.

The theory admits of very extensive algebraic developments, and applications in algebraical geometry and other parts of mathematics; but the fundamental properties of the functions may fairly be considered as included in what precedes.

Theory of Equations.

9. Tn the subject “Theory of Equations” the term equation is used to denote an equation of the form x η -p 1 x η ~ 1 . . . ±p n = 0, where p v p 2 . . . p n are regarded as known, and a? as a quantity to be determined: for shortness the equation is written fix) = 0 .

The equation may be numerical; that is, the coefficients p x , p”,. . p n are then numbers,—understanding by number a quantity of the form α + βi (a and β having any positive or negative real values whatever, or say each of these is regarded as susceptible of continuous variation from an indefinitely large negative to an indefinitely large positive value), and i denoting √~1.

Or the equation may be algebraical; that is, the coefficients are not then restricted to denote, or are not explicitly considered as denoting, numbers.

I. We consider first numerical equations. (Real theory, 10 to 14; Imaginary theory, 15 to 18.)

10. Postponing all consideration of imaginaries, we take in the first instance the coefficients to be real, and attend only to the real roots (if any); that is, p v p. 2 ,...p n are real positive or negative quantities, and a root a, if it exists, is a positive or negative quantity such that a n -p l cf~ 1 ... ± p n = 0, or say,∕(α) = 0. The fundamental theorems are given under Algebra, sections x., xiii., xiv.; but there are various points in the theory which require further development.

It is very useful to consider the curve y=f{x),— or, what would come to the same, the curve Ay=∕(z),—but it is better to retain the first-mentioned form of equation, drawing, if need be, the ordinate y on a reduced scale. For instance, if the given equation be x 3 - 6z 2 + 1 lx - 6'06 = 0, 2 then the curve y = z 3 - 6x 2 + llx — 6Ό6 is as shown in the figure at page 501, without any reduction of scale for the ordinate.

It is clear that in general y is a continuous one-valued function of a?, finite for every finite value of x, but becoming infinite when x is infinite; i.e., assuming throughout that the coefficient of x n is +1, then when x=∞. y = + ∞; but when x = — oo , then y = + ∞ or - ∞ , [9:8:500] according as n is even or odd; the curve cuts any line whatever, and in particular it cuts the axis (of z), in at most η points; and the value of x, at any point of intersection with the axis, is a root of the equation f (x) — 0.

If /8, α are any two values of x (a>β, that is, α nearer + ∞ ), then if f(β), f (a) have opposite signs, the curve cuts the axis an odd number of times, and therefore at least once, between the points x = β, x = a; but if /(/?), ∕(α) have the same sign, then between these points the curve cuts the axis an even number of times, or it may be not at all. That is, ∕(∕3), ∕(α) having opposite signs, there are between the limits β, a an odd number of real roots, and therefore at least one real root; but /(/?), ∕(α) having the same sign, there are between these limits an even number of real roots, or it may be there is no real root. In particular, by giving to β, a the values - αo , + ∞ (or, what is the same thing, any two values sufficiently near to these values respectively) it appears that an equation of an odd order has always an odd number of real roots, and therefore at least one real root; but that an equation of an even order has an even number of real roots, or it may be no real root.

If a be such that for x = or >α (that is, x nearer to + ∞ ) ∕(z) is always +, and β be such that forx= or < β (that is x nearer to - co ) fix') is always- - , then the real roots (if any) lie between these limits x = β, x = a ’ , and it is easy to find by trial such two limits including between them all the real roots (if any).

11. Suppose that the positive value δ is an inferior limit to the difference between two real roots of the equation; or rather (since the foregoing expression would imply the existence of real roots) suppose that there are not two real roots such that their difference taken positively is = or <8; then, γ being any value whatever, there is clearly at most one real root between the limits γ and γ + δ; and by what precedes there is such real root or there is not such real root, according as ∕(γ), f(γ + δ) have opposite signs or have the same sign. And by dividing in this manner the interval β to a into intervals each of which is = or <δ, we should not only ascertain the number of the real roots (if any), but we should also separate the real roots, that is, find for each of them limits γ, γ + δ between which there lies this one, and only this one, real root.

In particular cases it is frequently possible to ascertain the number of the real roots, and to effect their separation by trial or otherwise, without much difficulty; but the foregoing was the general process as employed by Lagrange even in the second edition (1808) of the Traite de la resolution des Equations Numériques ;^[4. The third edition (1826) is a reproduction of that of 1808; the first edition has the date 1798, but a large part of the contents is taken from memoirs of 1767-68 and 1770-71. ] the determination of the limit δ had to be effected by means of the “equation of differences” or equation of the order ⅛n(n - 1), the roots of which are the squares of the differences of the roots of the given equation, and the process is a cumbrous and unsatisfactory one.

12. The great step was effected by Sturm’s theorem (1835)—viz., here starting from the function/^), and its first derived function f ∖ x), we have (by a process which is a slight modification of that for obtaining the greatest common measure of these two functions) to form a series of functions

∕I≈),∕(≈)>Λ(≈)∙ ···/»(«)

of the degrees n,η-l, n - 2 0 respectively,—the last term ∕ n (x) being thus an absolute constant. These lead to the immediate determination of the number of real roots (if any) between any two given limits β, a; viz., supposing g >β (that is, a nearer to + ∞ ), then substituting suc cessively these two values in the series of functions, and attending only to the signe of the resulting values, the number of the changes of sign lost in passing from β to a is the required number of real roots between the two limits. In particular, taking β, α = — ∞ , + ∞ respectively, the signs of the several functions depend merely on the signs of the terms which contain the highest powers of x, and are seen by inspection, and the theorem thus gives at once the whole number of real roots.

And although theoretically, in order to complete by a finite number of operations the separation of the real roots, we still need to know the value of the before-mentioned limit δ; yet in any given case the separation may be effected by a limited number of repetitions of the process. The practical difficulty is when two or more roots are very near to each other. Suppose, for instance, that the theorem shows that there are two roots between 0 and 10; by giving to x the values 1, 2, 3,.. . successively, it might appear that the two roots were between 5 and 6; then again that they were between 5 3 and 5 4, then between 5 34 and 5'35, and so on until we arrive at a separation; say it appears that between 5 ’ 346 and 5 ’ 347 there is one root, and between 5 - 348 and 5349 the other root. But in the case in question δ would have a very small value, such as Ό02, and even supposing this value known, the direct application of the first-mentioned process would be still more laborious.

13. Supposing the separation once effected, the determination of the single real root which lies between the two given limits may be effected to any required degree of approximation either by the processes of Horner and Lagrange (which are in principle a carrying out of the method of Sturm’s theorem), or by the process of Newton, as perfected by Fourier (which requires to be separately considered).

First as to Horner and Lagrange. We know that between the limits β, a there lies one, and only one, real root of the equation; f(β) and f(a) have therefore opposite signs. Suppose any intermediate value is θ; in order to determine by Sturm’s theorem whether the root lies between β, θ, or between θ, a, it would be quite unnecessary to calculate the signs of f((h), J(f, f 2 (f). . .; only the sign of ∕(6) is required; for, if this has the same sign as /(/?), then the root is between β, θ ; if the same sign as /(a), then the root is between θ, a. We want to make θ increase from the inferior limit β, at which f(θ) has the sign of ∕(∕3), so long as∕(6) retains this sign, and then to a value for which it assumes the opposite sign; we have thus two nearer limits of the required root, and the process may be repeated indefinitely.

Horner’s method (1819) gives the root as a decimal, figure by figure; thus if the equation be known to have one real root between 0 and 10, it is in effect shown say that 5 is too small (that is, the root is between 5 and 6); next that 5 - 4 is too small (that is, the root is between 5'4 and 5 ’ 5); and so on to any number of decimals. Each figure is obtained, not by the successive trial of all the figures which precede it, but (a⅛ in the ordinary-process of the extraction of a square root, which is in fact Horner’s process applied to this particular case) it is given presumptively as the first figure of a quotient; such value may be too large, and then the next inferior integer must be tried instead of it, or it may require to be further diminished. And it is to be remarked that the process not only gives the approximate value a of the root, but (as in the extιaction of a square root) it includes the calculation of the function ∕(α) which should be, and approximately is, =0. The arrangement of the calculations is very elegant, and forms an integral part of the actual method. It is to be observed that after a certain number of decimal places have [9:8:501] been obtained, a good many more can be found by a mere division. It is iu the progress tacitly assumed that the roots have been first separated.

Lagrange’s method (1767) gives the root as a continued fraction a + v - ..., where a is a positive or negative o + c + integer (which may be = 0), but b, c, . .. are positive integers. Suppose the roots have been separated; then (by trial if need be of consecutive integer values) the limits may be made to be consecutive integer numbers: say they are a, α + 1; the value of x is therefore = α + , where y is positive and greater than 1; from the given equation for .τ, writing therein x = a + - , we form an equation of the same order for y, and this equation will have one, and only one, positive root greater than 1; hence finding for it the limits b, 5 + 1 (where b is = or >1), we have y = ⅛4--, where z is positive and greater than 1; and so on—that is, we thus obtain the successive denominators b, c, d.. of the continued fraction. The method is theoretically very elegant, but the disadvantage is that it gives the result in the form of a continued fraction, which for the most part must ultimately be converted into a decimal. There is one advantage in the method, that a commensurable root (that is, a root equal to a rational fraction) is found accurately, since, when such root exists, the continued fraction terminates.

14. Newton’s method (1711), as perfected by Fourier (1831), may be roughly stated as follows. If x = y be an approximate value of any root, and γ + h the correct value, then ∕(γ + Ä) = 0, that is,

Λ7) + ∣√'(7) + 1 ¾Γ(γ)÷...=0 5 and then, if h be so small that the terms after the second may be neglected, ∕(γ) + hf'(f) = 0 , that is, h = - ~ ∖ or f (λ ) *, y ) the new approximate value is x — γ - '> and so on, as often as we please. It will be observed that so far nothing has been assumed as to the separation of the roots, or even as to the existence of a real root; γ has been taken as the approximate value of a root, but no precise meaning has been attached to this expression. The question arises, what are the conditions to be satisfied by γ in order that the process may by successive repetitions actually lead to a certain real root of the equation; or say that, γ being an approximate value of a certain real root, the new value γ ~ff γ -) ma y be a more approximate value.

Referring to the figure, it is easy to see that that if OC represent the assumed value γ, then, drawing the ordinate CP to meet the curve in P, and the tangent PC' to meet the axis in C', we shall have OC' as the new approximate value of the root. But observe that there is here a real root OX, and that the curve beyond X is convex to the axis; under these conditions the point C' is nearer to X than was C; and, starting with C' instead of C, and proceeding in like manner to draw a new ordinate and tangent, and so on as often as we please, we approximate continually, and that with great rapidity, to the true value OX. But if C had been taken on the other side of X, where the curve is concave to the axis, the new point C' might or might not be nearer to X than was the point C; and in this case the method, if it succeeds at all, does so by accident only, i.e., it may happen that C' or some subsequent point comes to be a point C, such that OC is a proper approximate value of the root, and then the subsequent approximations proceed in the same manner as if this value had been assumed in the first instance, all the preceding work being wasted. It thus appears that for the proper application of the method we require more than the mere separation of the roots. In order to be able to approximate to a certain root a, = OX, we require to know that, between OX and some value ON, the curve is always convex to the axis (analytically, between the two values, f{x) and∕"(z) must have always the same sign). When this is so, the point C may be taken anywhere on the proper side of X, and within the portion XN of the axis; and the process is then the one already explained. The approximation is in general a very rapid one. If we know for the required root OX the two limits OM, ON such that from M to X the curve is always concave to the axis, while from X to N it is always convex to the axis,—then, taking D anywhere in the portion MX and (as before) C in the portion XN, drawing the ordinates DQ, CP, and joining the points P, Q by a line which meets the axis in D', also constructing the point C' by means of the tangent at P as before, we have for the required root the new limits OD', OC'; and proceeding in like manner with the points D', C', and so on as often as we please, we obtain at each step two limits approximating more and more nearly to the required root OX. The process as to the point D', translated into analysis, is the ordinate process of interpolation. Suppose OD = ∕3, OC = α, we have approximately f β + h) — f(β) + t whence if the root is β + h then λ = √*-≡Γ

P ct ) f(β)

Returning for a moment to Horner’s method, it may be remarked that the correction h, to an approximate value α, is therein found as a quotient the same or such as the quotient ∕(α)÷∕ ’ (α) which presents itself in Newton’s method. The difference is that with Horner the integer part of this quotient is taken as the presumptive value of ∕i, and the figure is verified at each step. With Newton the quotient itself, developed to the proper number of decimal places, is taken as the value of h ; if too many decimals are taken, there would be a waste of work; but the error would correct itself at the next step. Of course the calculation should be conducted without any such waste of work.

Next as to the theory of imaginaries.

15. It will be recollected that the expression number and the correlative epithet mιmerical were at the outset used in a wide sense, as extending to imaginaries. This extension arises out of the theory of equations by a process analogous to that by which number, in its original most restricted sense of positive integer number, was extended to have the meaning of a real positive or negative magnitude susceptible of continuous variation.

If for a moment number is understood in its most, restricted sense as meaning positive integer number, the [9:8:502] solution of a simple equation leads to an extension; ax - b = 0, gives %=~> a positive fraction, and we can in this manner represent, not accurately, but as nearly as we please, any positive magnitude whatever; so an equation

*

ax + b = 0 gives x = — , which (approximately as before)

represents any negative magnitude. We thus arrive at the extended signification of number as a continuously varying positive or negative magnitude. Such numbers may be added or subtracted, multiplied or divided one by another, and the result is always a number. Now from a quadric equation we derive, in like manner, the notion of a complex or imaginary number such as is spoken of above. The equation aτ 2 +1=0 is not (in the foregoing sense, number = real number) satisfied by any numerical value whatever of x ; but we assume that there is a number which we call i, satisfying the equation ι 2 + 1 = 0; and then taking a and b any real numbers, we form an expression such as a + bi, and use the expression number in this extended sense: any two such numbers may be added or subtracted, multiplied or divided one by the other, and the result is always a number. And if we consider first a quadric equation x 2 + px + q = (j where p and q are real numbers, and next the like equation, where p and q are any numbers whatever, it can be shown that there exists for x a numerical value which satisfies the equation; or, in other words, it can be shown that the equation lias a numerical root. The like theorem, in fact, holds good for an equation of any order whatever; but suppose for a moment that this was not the case; say that there was a cubic equation x i + px 2 ∙ + qx + r = 0, with numerical coefficients, not satisfied by any numerical value of x, we should have to establish a new imaginary j satisfying some such equation, and should then have to consider numbers of the form a 4- bj, or perhaps a + bj 4- cj- (a, b, c numbers α⅛ βi of the kind heretofore considered),—first we should be thrown back on the quadric equation x 2 4- px + q = 0, p and q being now numbers of the last-mentioned extended form —non constat that every such equation has a numerical root—and if not, we might be led to other imaginaries k, l, <fcc., and so on ad infinitum in inextricable confusion.

But in fact a numerical equation of any order whatever has always a numerical root, and thus numbers (in the foregoing sense, number = quantity of the form α + βi) form {what real numbers do not) a universe complete in itself, such that starting in it we are never led out of it. There may very well be, and perhaps are, numbers in a more general sense of the term (quaternions are not a case in point, as the ordinary laws of combination are not adhered to), but in order to have to do with such numbers (if any) we must start with them.

16. The capital theorem as regards numerical equations thus is, every numerical equation has a numerical root; or for shortness (the meaning being as before), every equation has a root. Of course the theorem is the reverse of self-evident, and it requires proof; but provisionally assuming it as true, we derive from it the general theory of numerical equations. As the term root was introduced in the course of an explanation, it will be convenient to give here the formal definition.

A number a such that substituted for x it makes the function x l η -p 1 x η ~ 1 .. . =tjι n to be = 0, or say such that it satisfies the equation fix) — 0, is said to be a root of the equation; that is, a being a root, we have

α n -p 1 α n ~ 1 . . . ±p, l = 0, or say J ∖ a) = 0; and it is then easily shown that x-ais a factor of the function∕(z), viz., that we have fix) = (x-a) f 1 (x), where ∕ 1 (x) is a function x n ~ 1 - q l x n ~ 2 . . . ÷ q n ~ l of the order n - 1, with numerical coefficients q v q 2 . . y, 1-1

In general a is not a root of the equation fi{x) — 0, but it may be so— i.e., f 1 {x) may contain the factor x - a; when this is so,∕(z) will contain the factor (x - a) 2 ; writing then fix') = (x - a) 2 ∕ 2 (z), and assuming that a is nota root of the equation fi(x) = 0, x = a is then said to be a double root of the equation fix) = 0; and similarly fix) may contain the factor (x - α) 3 and no higher power, and x — a is then a triple root; and so on.

Supposing in general that fix) = (x-a) α F(x) (α being a positive integer which may be =1, (x-a) a the highest power of x-a which divides fix), and F(ar) being of course of the order n - a), then the equation F(z) = 0 will have a root b which will be different from a; x-b will be a factor, in general a simple one, but it may be a multiple one, of F(jc), and fix) will in this case be = (x - a) α {x - bfi Φ(,t∙) {β a positive integer which may be = 1, {x-b)β the highest power of x-b in F(∙r) or fix), and Φ(∙z - ) being of course of the order n - a - β).. The original equation ∕(z) = 0 is in this case said to have α roots each = a, β roots each =b ; and so on for any other factors (x - cfi, &c.

We have thus the theorem— A numerical equation of the order n has in every case n roots, viz., there exist n numbers a, b, . . (in general all distinct, but which may arrange themselves in any sets of equal values), such that fix) = (x-a)(x - b){x - c)... identically.

If the equation has equal roots, these can in general be determined, and the case is at any rate a special one which may be in the first instance excluded from consideration. It is, therefore, in general assumed that the equation fix) = 0 has all its roots unequal.

If the coefficients ρ l , p 2 . . . are all or any one or more of them imaginary, then the equation fix) = 0, separating the real and imaginary parts thereof, may be written F(z) + iΦ(x) = 0, where F(z), Φ(x) are each of them a function with real coefficients; and it thus appears that the equation fix) = 0, with imaginary coefficients, has not in general any real root; supposing it to have a real root a, this must be at once a root of each of the equations F(x) = 0 and Φ(x) = 0.

But an equation with real coefficients may have as well imaginary as real roots, and we have further the theorem that for any such equation the imaginary roots enter in pairs, viz., α + ∕L' being a root, then a — βi will be also a root. It follows that if the order be odd, there is always an odd number of real roots, and therefore at least one real root.

17. In the case of an equation with real coefficients, the question of the existence of real roots, and of their separation, has been already considered. In the general case of an equation with imaginary (it may be real) coefficients, the like question arises as to the situation of the (real or imaginary) roots; thus, if for facility of conception we regard the constituents α, β of a root α 4- βi as the coordinates of a point in ρlano, and accordingly represent the root by such point, then drawing in the plane any closed curve or “contour,” the question is how many roots lie within such contour.

This is solved theoretically by means of a theorem of Cauchy’s (1837), viz., writing in the original equation x 4- iy in place of x, the function fix + iy) becomes = P 4- tQ, where P and Q are each of them a rational and integral function (with real coefficients) of (x, y). Imagining the point (x, y) to travel along the contour, and considering the number of changes of sign from - to + and from + to - of the fraction corresponding to passages of the fraction through zero (that is, to values for which P becomes = 0, disregarding those for which Q becomes = 0), the difference of these numbers gives the number of roots within the contour.
[9:8:503]

It is important to remark that the demonstration does not presuppose the existence of any root; the contour may be the infinity of the plane (such infinity regarded as a contour, or closed curve), and in this case it can be shown (and that very easily) that the difference of the numbers of changes of sign is = n ; that is, there are within the infinite contour, or (what is the same thing) there are in all n roots; thus Cauchy’s theorem contains really the proof of the fundamental theorem that a numerical equation of the nth order (not only has a numerical root, but) has precisely n roots. It would appear that this proof of the fundamental theorem in its most complete form is in principle identical with Gauss’s last proof (1849) of the theorem, in the form—A numerical equation of the nth order has always a root.^[5. The earlier demonstrations by Euler, Lagrange, &c., relate to the case of a numerical equation with real coefficients; and they consist in showing that such equation has always a real quadratic divisor, furnishing two roots, which are either real or else conjugate imaginaries a + βi (see Lagrange’s Équations Numériques). ]

But in the case of a finite contour, the actual determination of the difference which gives the number of real roots can be effected only in the case of a rectangular contour, by applying to each of it3 sides separately a method such as that of Sturm’s theorem; and thus the actual determination ultimately depends on a method such, as that of Sturm’s theorem.

Very little has been done in regard to the calculation of the imaginary roots of an equation by approximation; and the question is not here considered.

18. A class of numerical equations which needs to be considered is that of the binomial equations x η - a = 0 (α = α + ∕⅜ a complex number). The foregoing conclusions apply, viz., there are always n roots, which, it may be shown, are all unequal. And these can be found numeri cally by the extraction of the square root, and of an nth root, of real numbers, and by the aid of a table of natural sines and cosines.^[6. The square root of a + βi can be determined by the extraction of square roots of positive real numbers, without the trigonometrical tablee. ] For writing

α+0i= a/“ 2 + 3 2 i —τ⅛ „ + — τ-^ ∕ i ’

there is always a real angle λ (positive and less than 2π), such that its cosine and sine are= —„ and -∙ λ A--

√⅛ 2 + ∕3 2 √^ 2 +z3 2 respectively; that is, writing for shortness r JcP- ’ τ ∕3 2 = p, we have α + βi = ρ (cos λ + 7 sin λ), or the equation is x η = p (cos λ + i sin λ); hence observing that ^cos ^ i +i sin = cosλ + tsinλ, a value of x is = ^∕p^cos sin The formula really gives all the roots, for instead of λ we may write λ + 2s7τ, s a positive or negative integer, and then we have n ∣ [ λ + 2SJΓ . . λ + 2.97r∖ «= √p^cos~~ +ιsιn-— , which has the n values obtained by giving to s the values 0, 1, 2 . . . n — 1 in succession; the roots are, it is clear, represented by points lying at equal intervals on a circle. But it is more convenient to proceed somewhat differently; taking one of the roots tobe θ, so that θ n = a, then assuming x = θy, the equation becomes y n - 1 = 0, which equation, like the original equation, has precisely n roots (one of them being of course =1). And the original equation a,∙ n -α = 0 is thus reduced to the more simple equation x n -1=0j and although the theory of this equation is included in the preceding one, yet it is proper to state it separately.

The equation x n ~ 1 = 0 has it3 several roots expressed in the form 1, ω, ω 2 , . . . ω"^ 1 , where ω may be taken = cos ^~∙ + *' sin 2 -5 hi fact, ω having this value, any integer power ω i is = cos + i sin and we thence have (ω*) n = r nn ' ' cos 2πk + i sin 2τrk, = 1, that is, ω t is a root of the equation. The theory will be resumed further on.

By what precedes, we are led to the notion (a numerical) 1

of the radical «»regarded as an n- valued function; any one of these being denoted by :fa, then the series of values s ä, ω :j/ä, . .. ω n ~ 1 lf α ; or we may, if we please, use

— 1

a instead of a n as a symbol to denote the n- valued function.

As the coefficients of an algebraical equation may be numerical, all which follows in regard to algebraical equations is (with, it may be, some few modifications) applicable to numerical equations; and hence, concluding for the present this subject, it will be convenient to pass on to algebraical equations.

IL We consider secondly algebraical equations (19 to 34).

19. The equation is x n -p γ x n ~ y + ... ±p n =0, and we here assume the existence of roots, viz., we assume that there are n quantities a, b, c. . (in general all of them different, but which in particular cases may become equal in sets in any manner), such that x n -p 1 x n ~ 1 +. . ∑L p n - 0; or looking at the question in a different point of view, and starting with the roots a, b, c. . as given, we express the product of the n factors x-a, x-b,.Λn the foregoing form, and thus arrive at an equation of the order n having the n roots a, b, c . . In either case we have p 1 = 2α, p 2 = '2αb, . .ρ n ≈abc .; i.e., regarding the coefficients p v p 2 . . p n as given, then we assume the existence of roots α, δ, c,. . such that p 1 = 2«, &c.; or, regarding the roots as given, then we write p v p 2 , <fcc., to denote the functions Su, Suδ, &c.

As already explained, the epithet algebraical is not used in opposition to numerical; an algebraical equation is merely an equation wherein the coefficients are not restricted to denote, or are not explicitly considered as denoting, numbers. That the abstraction is legitimate, appears by the simplest example; in saying that the equation x 2 -px + q = 0 has a root x = ⅛(p + l fp 2 -4q),we mean that writing this value for x the equation becomes an identity, {⅛(j p + f Jp 2 - 4⅛)} 2 -p{⅛ (p + √P 2 - 4<∕)} + 7 = 0; and the verification of this identity in nowise depends upon p and q meaning numbers. But if it be asked what there is beyond numerical equations included in the term algebraical equation, or, again, what is the full extent of the meaning attributed to the term—the latter question at any rate it would be very difficult to answer; as to the former one, it may be said that the coefficients may, for instance, be symbols of operation. As regards such equations, there is certainly no. proof that every equation has a root, or that an equation of the ??th order has n roots; nor is it in any wise clear what the precise signification of the statement is. But it is found that the assumption of the existence of the n roots can be made without contradictory results; conclusions derived from it, if they involve the roots, rest on the same ground as the original assumption; but the conclusion may be independent of the roots altogether, and in this case it is undoubtedly valid; the reasoning, although actually conducted by aid of the assumption (and, it may be, most easily and elegantly in this manner), is really independent [9:8:504] of the assumption. In illustration, we observe that it is allowable to express a function of p and q as follows,—that is, by means of a rational symmetrical function of a and δ; this can, as a fact, be expressed as a rational function of a + b and ab-, and if we prescribe that a + b and ab shall then be changed into p and q respectively, we have the required function of ρ, q. That is, we have F (a, /3) as a representation of f (p, q), obtained as if we hadjo = α + δ, q = ab, but without in any wise assuming the existence of the a, b of these equations.

20. Starting from the equation x”-p 1 χ n ^ 1 + . · · =x-α.x-b. &c.

or the equivalent equations p l = 2«, àc., we find α n -p 1 α" -1 + . . =0, δ n -p 1 0 n -ι + . . =0;

(it is as satisfying these equations that a, b . . are said to be the roots of x n - p i x n ' γ + .. =0); and conversely from the last-mentioned equations, assuming that a,b.. are all different, we deduce p 1 = 2α, p 2 = 2αb, &c.

and

αj n -p 1 z" -1 + . ..≈x-a.x-b. &c.

Observe that if, for instance, a = b, then the equations α n - p 1 a n ~ 1 + . . = 0, b n - p l b n ~ 1 + ... = 0 would reduce themselves to a single relation, which would not of itself express that a was a double root,—that is, that (x — a) 2 was a factor of x n -ρ 1 x n ~ 1 + &c.; but by considering b as·the limit of a + h, h indefinitely small, we obtain a second equation nα n ^ 1 - (n-V)p 1 α n ~ 2 +. . . = 0, which, with the first, expresses that a is a double root; and then the whole system of equations leads as before to the equations p λ = 2,a, &c. But the existence of a double root implies a certain relation between the coefficients; the general case is when the roots are all unequal.

We have then the theorem that every rational symmetrical function of the roots is a rational function of the coefficients. This is an easy consequence from the less general theorem, every rational and integral symmetrical function of the roots is a rational and integral function of the coefficients.

In particular, the sums of the powers 2α 2 , S<t 3 , <fcc., are rational and integral functions of the coefficients.

The process originally employed for the expression of other functions 2<ι α δ∕ 3 , &c., in terms of the coefficients is to make them depend upon the sums of powers: for instance, — 'la ,l S.f i - '2,a a+ l 3 ; but this is very objectionable; the true theory consists in showing that we have systems of equations

Pi -2α, ∖ p i = 2αδ

(Pi = 2α≡+22aδ,

( Ps = lS,c-bc, ) Pi P∙ι = ~2a 2 b + 32αδc,

( p 1 3 = 2« 3 + 32α 2 δ + 62αδc, where in each system there are precisely as many equations as there are root-functions on the right-hand side— e.g., 3 equations and 3 functions '½abc, 2α 2 δ, 2α 3 . Hence in each system the root-functions can be determined linearly in terms of the powers and products of the coefficients:

f 2ftδ ≈ p i ,

1 2α 2 =p 1 2 -2p i ,

!2αδc = p 2 ,

2α 2 δ = PιP 2 -3p 3 ,

S® = p 1 3 -3p l p 2 + 3p 3 , and so on. The older process, if applied consistently, would derive the originally assumed value Ιab, =p.,, from the two equations 2«=p, Sα 2 =7> 1 2 — 2p 0 ; f.e., we have 22αό = 2α.2α - 2α 2 , = pf - (p 1 2 - 2∕> 2 ), = 2p 2 ,

21. It is convenient to mention here the theorem that, x being determined as above by an equation of the order n, any rational aud integral function whatever of x, or more generally any rational function which does not become infinite in virtue of the equation itself, can be expressed as a rational and integral function of x, of the order n - 1, the coefficients being rational functions of the coefficients of the equation. Thus the equation gives x n a function of the form in question; multiplying each side by z, and on the right-hand side writing for xP its foregoing value, we have x n+1 , a function of the form in question; and the like for any higher power of x, and therefore also for any rational and integral function of x. The proof in the case of a rational non-integral function is somewhat more complicated. The final result is of the form = I(z), or say ≠(∙r) - ι∕∕(x)I(z) = 0, where <∕>, ψ, I are rational and integral functions; in other words, this equation, being true if only∕(z) — 0, can only be so by reason that the left-hand side contains f (x) as a factor, or we must have identically <∕>(z) — ψ(x)I(x) = M(.cj/’(z). And it is, moreover, clear that the equation = I(z), being satisfied if only fix') = 0, must be satisfied by each root of the equation.

From the theorem that a rational symmetrical function of the roots is expressible in terms of the coefficients, it at once follows that it is possible to determine an equation (of an assignable order) having for its roots the several values of any given (unsymmetrical) function of the roots of the given equation. For example, in the case of a quartic equation, roots (a, b, c, d), it is possible to find an equation having the roots ab, ac, ad, be, bd, cd (being therefore a sextic equation): viz., in the product

(y - αb')(y - ac')( t y - αrf)(y - bc){y - δd)(y - al) the coefficients of the several powers of y will be symmetrical functions of a, b, c, d and therefore rational and integral functions of the coefficients of the quartic equation; hence, supposing the product so expressed, and equating it to zero, we have the required sextic equation. In the same manner can be found the sextic equation having the roots (α — δ) 2 , (α - c) 2 , (α - tf) 2 , (f> - c) 2 , (δ — if) 2 , (c - d) 2 , which is the equation of differences previously referred to; and similarly we obtain the equation of differences for a given equation of any order. Again, the equation sought for may be that having for its n roots the given rational functions φfι) , φ{b), ... of the several roots of the given equation. Any such rational function can (as was shown) be expressed as a rational and integral function of the ordern—1; and, retaining x in place of any one of the roots, the problem is to find y from the equations x n - j p 1 z n ^ 1 ... = 0 , and y = M 0 x" -1 + M 1 a∙ w-2 + . ., or, what is the same thing, from these two equations to eliminate x. This is in fact Tschirnhausen’s transformation (1683).

22. In connexion with what precedes, the question arises as to the number of values (obtained by permutations of the roots) of given unsymmetrical functions of the roots, or say of a given set of letters: for instance, with roots or letters (<7, b, c, d) as before, how many values are there of the function ab + cd, or better, how many functions are there of this form? The answer is 3, viz., ab + cd, ac + bd, ad + bc ; or again we may ask whether, in the case of a given number of letters, there exist functions with a given number of values, 3-valued, 4-valued functions, &c.

It is at once seen that for any given number of letters there exist 2-valued functions; the product of the differences of the letters is such a function; however the letters are interchanged, it alters only its sign; or say the two values are Δ, - A . And if P, Q are symmetrical functions [9:8:505] of the letters, then the general form of such a function is P + QΔ; this has only the two values P + Q∆, P - Q∆ .

In the case of 4 letters there exist (as appears above) 3-valued functions: but in the case of 5 letters there does not exist any 3-valued or 4-valued function; and the only 5-valued functions are those which are symmetrical in regard to four of the letters, and can thus be expressed in terms of one letter and of symmetrical functions of all the letters. These last theorems present themselves in the demonstration of the non-existence of a solution of a quintic equation by radicals.

The theory is an extensive and important one, depending on the notions of substitutions and cΛ groups. ^[7. A substitution is the operation by which we pass from the primitive arrangement of n letters to any other arrangement of the same letters: for instance, the substitution (liιi i ) means that α is to be (abed changed into b, b into c, c into d, d into a. Substitutions may, οi course, be represented by single letters a,β , . . ≈≤ ’ ∙- ∙ b ** substitution which leaves the letters unaltered. Two or more substitutions may be compounded together and give rise to a substitution; i.e., performing upon the primitive arrangement first the substitution β and then upon the result the substitution α, we have the substitution aβ. Substitutions are not commutative; thus, aß is not in general = ßa; but they are associative, aβ.y = a.βγ, so that aβy has a determinate meaning. A substitution may be compounded any number of times with itself, and we thus have the powers α, a.. &c. Since the num ber of substitutions is limited, some power a υ must be =1, or as this may be expressed every substitution is a root of unity. A group of substitutions is a set such that each two of tlιem compounded together in either order gives a substitution belonging to the set; every group includes the substitution unity, so that we may in general speak of a group l,α,0,.. (the number of terms is the order of the group). The whole system of the 1.2.3... n substitutions which can be performed upon the n letters is obviously a group: the order of every other group which can be formed out of these substitutions is a submultiple of tlιis number; but it is not conversely true that a group exists the order of which is any given submultiple of this number. In the case of a determinant the substitutions which give rise to the positive terms form a group the order of which is =⅜1.2.3...n. For any function of the n-letters, the whole series of substitutions which leave the value of the functions unaltered form a group; and thence also the number of values of the function is = 1.2.3...n divided by the order of the group. ]

23. Returning to equations, we have the very important theorem that, given the value of any unsymmetrical function of the roots, e.g., in the case of a quartic equation, the function ab + cd, it is in general possible to determine rationally the value of any similar function, such as (α + 5) 3 + (c + d) 3 .

The a priori ground of this theorem may be illustrated by means of a numerical equation. Suppose that the roots of a quartic equation are 1, 2, 3, 4, then if it is given that αδ + C(7=14, this in effect determines a, b to be 1, 2 and c,d tobe 3,4 (viz. α= 1,5 = 2 or α = 2,5= 1, andc = 3,√ = 4 or c = 3, d = 4) or else a, b to be 3, 4 and c, d to be 1,2; and it therefore in effect determines (a + b) 3 + (c + T) 3 to be = 370, and not any other value; that is, (α + b) 3 + (c + <Z) 3 , as having a single value, must be determinable rationally. And we can in the same way account for cases of failure as regards particular equations; thus, the roots being 1,2, 3, 4 as before, a 2 b = 2 determines a to be =1 and b to be -- 2 , but if the roots had been 1, 2, 4,16 thenα 2 5 = 16 does not uniquely determine α,ά but only makes them to be 1,16 or 2,4 respectively.

As to the a posteriori proof, assume, for instance.

∕∣=α⅛+cd, y j = (ft + δ) 3 + (c+d) 3 , i i ≈αc+bd, y 2 = (α + c) 3 + (⅛ + d) 3 , t i = aιl + bc, y 3 = (α + d) 3 + i δ + c) 3 ι

then y j +y 2 + y 3 , ^ι + ⅛ + ⅛ . G⅛'ι + ⅛ + ‰ will be respectively symmetrical functions of the roots of the quartic, and therefore rational and integral functions of the coefficients; that is, they will be known.

Suppose for a moment that t v t 2 , f 3 are all known, then the equations being linear in y 1 , y v ι∕ 3 these can be expressed rationally in terms of the coefficients and of t l , t 2 ,t i ', that is, y- i , y 2 > y 3 will be known. But observe further that y 1 is obtained as a function of t 1 , t 2 , t 3 symmetrical as regards f 2 ,7 3 ; it can therefore be expressed as a rational function of ∕ 1 and of 7 2 -M 3 , i. 2 t 3 , and thence as a rational function of t x and of t l + t., +t 3 , 7j∕ 2 ÷ t i t 3 + t 2 t 3 , tjl l f 3 , ) but these last are symmetrical functions of the roots, and as such they are expressible rationally in terms of the coefficients; that is, 1 J ∖ will be expressed as a rational function of ∕ 1 and of the coefficients; or f 1 (alone, not t 2 or t 3 ) being known, g i will be rationally determined.

24. We now consider the question of the algebraical solution of equations, or, more accurately, that of the solution of equations by radicals.

In the case of a quadric equation x~ -px + g , = 0, we can by the assistance of the sign s ∕( ) or ( )i find an ex pression for X as a two-valued function of the coefficients ρ, q such that substituting this value in the equation, the equation is thereby identically satisfied; it has been found that this expression is χ=⅛[p± √F 7 ^⅞}, and the equation is on this account said to be algebraically solvable, or more accurately solvable by radicals. Or we may by writing x = ~⅛p + z, reduce the equation to ∙s 2 = ∣(p 2 - 4ç) viz., to an equation of the form z 2 = α; and in virtue of its being thus reducible we say that the original equation is solvable by radicals. And the question for an equation of any higher order, say of the order n, is, can we by means of radicals (that is by aid of the sign ζ∕( ) or ( ) «, using as many as we please of such signs and with any values of m) find an π-valued function (or any function) of the coefficients which substituted for x in the equation shall satisfy it identically.

It will be observed that the coefficients p,q.. are not explicitly considered as numbers, but even if they do denote numbers, the question whether a numerical equation admits of solution by radicals is wholly unconnected with the before-mentioned theorem of the existence of the n roots of such an equation. It does not even follow that in the case of a numerical equation solvable by radicals the algebraical solution gives the numerical solution, but this requires explanation. Consider first a numerical quadric equation with imaginary coefficients. In the formula i≡ = ⅞(p= fc x4* 2 -⅜)> substituting for p,q their given numerical values, we obtain for x an expression of the form x = α + βi± √γ +δz, where α,/?, γ, δ are real numbers. This expression substituted for x in the quadric equation would satisfy it identically, and it is thus an algebraical solution; but there is no obvious a priori reason why x ∕γ + δt should have a value = c + di, where c and d are real numbers calculable by the extraction of a root or roots of real numbers; however the case is (what there was no a priori right to expect) that s ∕γ+ δ∕ has such a value calculable by means of the radical expressions √{ x ∕γ 2 + δ 2 ± γ}: and hence the algebraical solution of a numerical quadric equation does in every case give the numerical solution. The case of a numerical cubic equation will be considered presently.

25. A cubic equation can be solved by radicals. Taking for greater simplicity the cubic in the reduced form x i + qx - r = 0, and assuming x = a + b, this will be a solution if only ‘dab = q and a 3 + b 3 = r, equations which give (α 3 - 5 3 ) 2 = r 2 - ∙^ 7 √2 3 , a quadric equation solvable by radicals, and giving a 3 - b 3 = fr 2 — -⅛q 3 , a two-valued function of the coefficients: combining this with α 3 + b 3 = r, we have α 3 = ⅜(r + x ∕r 2 - 5 4 t <7 3 ), a two-valued function: we then have a by means of a cube root, viz.,

«- ^{⅜0∙+
[9:8:506]

a six-valued function of the coefficients; but then, writing q = ^-, we have, as may be shown, a + b a three-valued function of the coefficients; and x = a + b is the required solution by radicals. It would have been wrong to complete the solution by writing b≈ 4∕{^-

for then a + b would have been given as a 9-valued function having only 3 of its values roots, and the other 6 values being irrelevant. Observe that in this last process we make no use of the equation ⅛ab = q, in its original form, but use only the derived equation 27α 3 Λ 3 = g ,3 , implied in, but not implying, the original form.

An interesting variation of the solution is to write x = ab(a + b), giving a i b ∖ a i + b 3 ) = r and 3α 3 0 3 = j, or say α 3 + ⅛ s = —, α 3 ⅛ 3 = ^ l s q ; and consequently

α 3 =∣(r + √r 2 -i r 7 3 )> δ 3 = ∣(r- JP-Hq'}, i.e, here α 3 , b 3 are each of them a two valued function, but as the only effect of altering the sign of the quadric radical is to interchange α 3 , b 3 , they may be regarded as each of them one-valued; a and b are each of them 3∙valued (for observe that here only a 3 b 3 , not ab, is given); and ab (a + b) thus is in appearance a 9-valued function; but it can easily be shown that it is (as it ought to be) only 3-valued.

In the case of a numerical cubic, even when the coefficients are real, substituting their values in the expression t∕{⅜b∙+ J>'-Hq 3 )} + l·l+ i ξ∕{⅛(r÷ √r 2 -∕ τ i i )}, this may depend on an expression of the form ^∕γ + δz where γ and δ are real numbers (it will do so if r 2 - - s f r q 3 is a negative number), and then we cannot by the extraction of any root or roots of real positive numbers reduce ^∕γ + δ∕ to the form c + di, c and d real numbers; hence here the algebraical solution does not give the numerical solution, and we have here the so-called “irreducible case” of a cubic equation. By what precedes there is nothing in this that might not have been expected; the algebraical solution makes the solution depend on the extraction of the cube root of — a number, and there was no reason for expecting this to be a real number. It is well known that the case in question is that wherein the three roots of the numerical cubic equation are all real; if the roots arc two imaginary, one real, then contrariwise the quantity under the cube root is real; and the algebraical solution gives the numerical one.

The irreducible case is solvable by a trigonometrical formula, but this is not a solution by radicals: it consists in effect in reducing the given numerical cubic (not to a cubic of the form z 3 = σ, solvable by the extraction of a cube root, but) to a cubic of the form 4z 3 - 3r = α, corresponding to the equation 4cos 3 0 - 3cos0 = cos30 which serves to determine cosØ when cos30 is known. The theory is applicable to an algebraical cubic equation; say that such an equation, if it can be reduced to the form 4.r 3 - 3;r = or, is solvable by “trisection”—then the general cubic equation is solvable by trisection.

26. A quartic equation is solvable by radicals: and it is to be remarked that the existence of such a solution depends on the existence of 3 valued functions such as ab + cd of the four roots (a, b, c, d) : by what precedes ab + cd is the root of a cubic equation, which equation is solvable by radicals: hence ab + cd can be found by radicals; and since abed is a given function, ab and cd can then be found by radicals. But by what precedes, if ab be known then any similar function, say a + b, is obtainable rationally; and then from the values of a 4- b and ab we may by radicals obtain the value of a or b, that is, an expression for the root of the given quartic equation: the expression ultimately obtained is 4-valued, corresponding to the different values of the several radicals which enter therein, and we have thus the expression by radicals of each of the four roots of the quartic equation. But when the quartic is numerical the same thing happens as in the cubic, and the algebraical solution does not in every case give the numerical one.

It will be understood from the foregoing explanation as to the quartic how in the next following case, that of the quintic, the question of the solvability by radicals depends on the existence or non-existence of k- valued functions of the five roots (a, b, c,d,e) ; the fundamental theorem is the one already stated, a rational function of five letters, if it has less than 5, cannot have more than 2 values, that is, there are no 3-valued or 4-valued functions of 5 letters: and by reasoning depending in part upon this theorem, Abel (1824) showed that a general quintic equation is not solvable by radicals; and a fortiori the general equation of any order higher than 5 is not solvable by radicals.

27. The general theory of the solvability of an equation by radicals depends fundamentally on Vandermonde’s remark (1770) that, supposing an equation is solvable by radicals, and that we have therefore an algebraical expression of x in terms of the coefficients, then substituting for the coefficients their values in terms of the roots, the resulting expression must reduce itself to any one at pleasure of the roots a,b,ο ., ; thus in the case of the quadric equation, in the expression x = ⅛(p+ >Jp i - 4<∕), substituting for p and q their values, and observing that (α + 0) 2 -4αδ = (a-b) 2 , this becomes x=⅛{a + b+ J(a-b) 2 }, the value being a or b according as the radical is taken to be + (a - b) or - (a - b).

So in the cubic equation .r 3 -px 2 + qx- r = 0, if the roots are a,b,c, and if ω is used to denote an imaginary cube root of unity, ω 2 + ω + I = 0, then writing for shortness p = a + b + c, L = n + ωδ + ω 2 c, M = a + ω 2 6 + ωc , it is at once seen that LM, L 3 + M 3 , and therefore also (L 3 - M 3 ) 2 are symmetrical functions of the roots, and consequently rational functions of the coefficients: hence

⅜{L 3 + M 3 + √(L 3 -M 3 ) 2 }

is a rational function of the coefficients, which when these are replaced by their values as functions of the roots becomes, according to the sign given to the quadric radical, = L 3 or M 3 : taking it = L 3 , the cube root of the expression has the three values L,ωL,ω 2 L; and LM divided by the same cube root has therefore the values M,ω 2 M,ωM; whence finally the expression

⅜[p + s √{⅜(L 3 + M 3 + √(L 3 -M 3 ) 2 )}

. + LM÷ 4 √{ ⅛L s + M 3 + √(L 3 -M 3 ) 2 )}]

has the three values

∣j(p + L + M), ⅛(p + «L + ⅛, 2 M), ^(p + ω 2 L 4- <⅛M); that is. these are = a, b, c respectively. If the value M 3 had been taken instead of L 3 , then the expression would have had the same three values a, b, c. Comparing the solution given for the cubic x i + qx-r = 0, it will readily be seen that the two solutions are identical, and that the function r 2 - f τ q 3 under the radical sign must (by aid of the relation p = 0 which subsists in this case) reduce itself to (L 3 — M 3 ) 2 ; it is only by each radical being equal to a rational function of the roots that the final expression can become equal to the roots a, b, c respectively.

28. The formulae for the cubic were obtained by Lagrange (1770-71) from a different point of view. Upon examining and comparing the principal known methods for [9:8:507] the solution of algebraical equations, he found that they all ultimately depended upon finding a “resolvent” equation of which the root is a + ωb 4- ω 2 c + ω 3 cZ +. . . , ω being an imaginary root of unity, of the same order as the equation; e.g., for the cubic the root is α + ωf> + ω 2 c, ω an imaginary cube root of unity. Evidently the method gives for L 3 a quadric equation, which is the “resolvent” equation in this particular case.

For a quartic the formulae present themselves in a somewhat different form, by reason that 4 is not a prime number. Attempting to apply it to a quintic, we seek for the equation of which the root is (α 4-ω5 + ω 2 c∙ + ω 3 √ + ω 4 e), ω an imaginary fifth root of unity, or rather the fifth power thereof (a 4- ωύ 4- ω 2 c + ω 3 d + ω 4 β) 5 ; this is a 24-valued function, but if we consider the four values corresponding to the roots of unity ω, ω 2 , ω 3 , ω 4 , viz., the values

(α + ω b+ ω 2 C + ω 3 iZ + ω 4 e) β , (il + ω 2 b + α> 4 c + ω cl + ω 3 β) s , (« 4∙ ω 3 0 + ω C 4- ω 4 d + ω 2 C) s , (<l + ω 4 δ + ω , C -t- ω^d 4^ ω ej ’ , any symmetrical function of these, for instance their sum, is a six-valued function of the roots, and may therefore be determined by means of a sextic equation, the coefficients whereof are rational functions of the coefficients of the original quintic equation; the conclusion being that the solution of an equation of the fifth order is made to de pend upon that an equation of the sixth order. This is, of course, useless for the solution of the quintic equation, which, as already mentioned, does not admit of solution by radicals; but the equation of the sixth order, Lagrange’s resolvent sextic, is very important, and is intimately connected with all the later investigations in the theory.

29. It is to be remarked, in regard to the question cl solvability by radicals, that not only the coefficients are taken to be arbitrary, but it is assumed that they are represented each by a single letter, or say rather that they are not so expressed in terms of other arbitrary quantities as to make a solution possible. If the coefficients are not all arbitrary, for instance, if some of them are zero, a sextic equation might be of the form x c '+ l>x i + cx 2 + d = 0, and so be solvable as a cubic; or if the coefficients of the sextic are given functions of the six arbitrary quantities a, b, c, d, e, f, such that the sextic is really of the form (x 2 + ax 4- b)(x i + ex 3 + dx 2 + ex +∕) = 0, then it breaks up into the equations x 2 ->- ax + b — 0, x 4 4- cx 3 + dx 2 + ex +f≈ 0, and is consequently solvable by radicals; so also if the form is (x - a) {x - 5)(z ι - c)(z - T)(x - e) (x -f) = 0, then the equation is solvable by radicals,—in this extreme case rationally. Such cases of solvability are self-evident; but they are enough to show that the general theorem of the non-solvability by radicals of an equation of the fifth or any higher order does not in any wise exclude for such orders the existence of particular equations solvable by radicals, and there are, in fact, extensive classes of equations which are thus solvable; the binomial equations x n - 1-0 present an instance.

30. It has already been shown how the several roots of the equation x n -1=0 can be expressed in the form

2sτ . . 2sτ , , . .

cos — + ι sin — , but the question is now that of the η n algebraical solution (or solution by radicals) of this equation. There is always a root = 1; if ω be any other root, then obviously ω, ω 2 ,.. .. ω "" 1 are all of them roots; af-1 contains the factor x-l, and it thus appears that ω, ω 2 ,. .. ω r ∙^^ 1 are the n— 1 roots of the equation x"- 1 + x"- j + . . . + « + 1-0; we have, of course, ω"^ 1 + ω n * 2 . .. + ω + 1 = 0.

It is proper to distinguish the cases n prime and n composite; and in the latter case there is a distinction according as the prime factors of n are simple or multiple. By way of illustration, suppose successively n= 15 and n = 9; in the former case, if α be an imaginary root of z 3 - 1 = 0 (or root of x 2 + x + 1 = 0), and β an imaginary root of z 5 - 1 = 0 (or root of z 4 + z 3 + x 2 + x + 1 = 0), then ω may be taken = αβ ; the successive powers thereof, aβ, a 2 β 2 , β 3 1 aβ i , a 2 , β, aβ 2 , a 2 β 3 , β i , a, a 2 β, β 2 , aβ 3 , a 2 β i , are the roots of z 14 + z 13 . . . . + z+ 1 = 0; the solution thus depends on the solution of the equations z 3 - 1 = 0 and x 5 - 1 = 0. In tbe latter case, if α be an imaginary root of z 3 - 1 = 0 (or root of x 2 + x + 1 = 0), then the equation x 9 - 1 = 0 gives x 3 - 1, α, or a 2 ; x? = 1 gives x = 1, a, or a 2 ; and the solution thus depends on the solution of tbe equations x 3 - 1 = 0, x 3 -a-0, x 3 -α 2 = 0. The first equation has the roots 1, α, α 2 ; if β be a root of either of the others, say if β 3 = a, then assuming ω = β, the successive powers are β, β 2 , α, aβ, aβ 2 , a 2 , a 2 β, a 2 β 2 , which are the roots of the equation x s + x t . . . + x + 1 = 0.

Ic thus appears that the only case which need be con sidered is that of n a prime number, and writing (as is more usual) r in place of ω, we have r, r 2 , r 3 ,.. . r"^^ 1 as the (⅛ - 1) roots of the reduced equation x n-1 + x n -2 i t t ,+χ + l = 0; then not only r n - 1 — 0, but also r n ~ 1 + r n ~ 2 .. . + r + 1 = 0.

31. The process of solution due to Gauss (1801) depends essentially on the arrangement of the roots in a certain order, viz., not as above, with tbe indices of r in arithmetical progression, but with their indices in geometrical progression; the prime number n has a certain number of prime roots g, which are such that g n ~ 1 is the lowest power of g, which is 1 to the modulus n ; or, what is tbe same thing, that the series of powers 1, g, g 2 ... g n ~ ∖ each divided by n, leave (in a different order) the remainders 1, 2, 3 . .. n - 1; hence giving to r in succession the indices 1, g, g 2 . .. g n ~ 2 , we have, in a different order, the whole series of roots r. r 2 , r 3 ... r n ~ ∖

In the most simple case, n = 5, tbe equation to be solved is z 4 + x 3 + x 2 + x + 1 = 0; here 2 is a prime root of 5, and the order of the roots is r, r 2 , r i , r 3 , The Gaussian process consists in forming an equation for determining the periods P 1 , P 2 , = r + r 4 and r 2 + r 3 respectively,—these being such that the symmetrical functions P 1 + P.,, P 1 P 2 are rationally determinable: in fact P 1 + P 2 = — 1, P 1 P 2 = (r + r 4 )(r 2 + r 3 ), = r 3 + r 4 + r 0 + r 7 , = r 3 + r 4 + r + r 2 , = -1. P 1 , P 2 are thus the roots of « 2 + «-1=0; and taking them to be known, they are themselves broken up into subperiods, in the present case single terms, r and r 4 for P 1 , r 2 and r 3 for P 2 ; the symmetrical functions of these are then rationally determined in terms of P 1 and P 2 ; thus r + r 4 = P 1 , r.r 4 =1, or r, r 4 are the roots cf u 2 ∙- P·pt + 1 = 0. The mode of division is more clearly seen for a larger value of n; thus, for n = 7 a prime rout is = 3, and the arrangement of the roots is r, r 3 , r 2 , r 6 ,7∙ 4 , r 5 . We may form either 3 periods each of 2 terms, P 1 , P 2 , P 3 = r + r 6 , r 3 -+- r 4 , r 2 + √∙ 5 respectively; or else 2 periods each of 3 terms, P 1 , P 2 = r + r 2 + r 4 , r 3 + j∙ 6 + r 5 respectively; in each case the symmetrical functions of the periods are rationally determinable: thus in the case of the two periods P 1 + P 2 =-1, P 1 P 2 = 3 + r + r 2 + r 3 + r 4 + r 5 + r β , = 2; and the periods being known the symmetrical functions of the several terms of each period are rationally determined in terms of the periods, thus r + r 2 + r 4 = P 1 , r.r 2 + r. r i + r 2 . r 4 — P 2 , r. r 2 . r 4 = 1.

The theory was further developed by Lagrange (1808), who, applying his general process to the equation in question, x n ^^ 1 + x n ~ 2 . . + z + 1 = 0 (the roots a, b, c . . being the several powers of r, the indices in geometrical progression as above), showed that the function (a + ωb + ω 2 c + . .)"" 1 was in this case a given function of « with integer co [9:8:508] efficients. Reverting to the before-mentioned particular equation x i + 3? + x 2 + x + 1 = 0, it is very interesting to compare the process of solution with that for the solution of the general quartic the roots whereof are a, b, c, d.

Take ω, a root of the equation ω 4 - 1 = 0 (whence ω is — 1, - ], i, or - i, at pleasure), and consider the expression (« + ωb + ω 2 C 4- ω 3 d) i , the developed value of this is

∙≈ α 4 + b i + c 4 + d i + 6(α 2 c 2 + δ 2 iZ 2 ) +1 t Bα-bd + b"eα + c t db -fd 2 αc)

+ α∙ { 4(α 3 ⅛ + b 3 e + c 3 + d 3 a) +1 2(aPcd + b 2 da + c~ab + d' 2 bc) J + ω 2 { 6(α ’ δ 2 + δ 2 c 2 + c 2 d 2 + d i a 3 ) + 4(α 3 c + b 3 d + c 3 a + d 3 b) + 24αδcd } + ω 3 [ 4(α 3 d + b 3 a + c 3 b + d 3 c) +1 2(a 2 bc + b t cd + c 2 da + d 2 ab)} that is, this is a 6-valued function of a, b, c, d, the root of a sextic (which is, in fact, solvable by radicals; but this is not here material).

If, however, a, b, c, d denote the roots r, r 2 , r i , r 3 of the special equation, then the expression becomes r i + r 3 4- r + r 2 + 6(1 +1 ) + 12(r 2 4- r 4 + r 3 + r)

+ ω [4(1 + 1 +1 +1 ) + 12(r 4 +r 3 + r +r 2 )} + or { 6(r + r 2 + r i + r 3 ) + 4 (r 2 + r 4 + r 3 + r )} + ω 3 {4(r+r s + r 4 + r 3 ) + 12(r 3 + r + r 2 + r 4 )} viz., this is

= — 1 + 4cu + 14α∣ 2 - 16ω 3 , a completely determined value. That is, we have

(r + α>∕∙ 2 + w 2 r 4 + ω s r 3 ) 4 = - 1 + 4ω +14ω 2 - 16ω 3 , which result contains the solution of the equation. If ω = 1, we have (r + r 2 + r 4 + r 3 ) 4 = 1, which is right; if ω= - 1, then (r + r i - r 2 - r 3 ) 4 = 25; if ω = i, then we have {r -r 4 + t (r 2 - r 3 )} 4 = - 15 + 20i; and if ω = — i, then {r-r 4 -z (r 2 -r 3 )} 4 = -15-20i; the solution may be completed without difficulty.

The result is perfectly general, thus :— n being a prime number, r a root of the equation x τ *^^ 1 + x η ~∙.... + χ + 1 = 0, ω a root of ω 1, ^ l -1 = 0, and g a prime root of g n ~ 1 '£ 1 (mod. n), then

(r+ωr j ,. . . + w n-ι√' -2 )n-ι

is a given function M o + M 1 ω . .. + M n . s ω n ^ 2 with integer coefficients, and by the extraction of (n - 1)th roots of this and similar expressions we ultimately obtain r in terms of ω, w hich is taken to be known; the equation x n - 1 = 0, n a prime number, is thus solvable by radicals. In particular, if n - 1 be a power of 2, the solution (by either process) requires the extraction of square roots only; and it was thus that Gauss discovered that it was possible to construct geometrically the regular polygons of 17 sides and 257 sides respectively. Some interesting developments in regard to the theory were obtained by Jacobi (1837); see the memoir “Ueber die Kreistheilung, u.s.w.,” Crelle, t. XXX. (1846).

The equation af ’ ~ 1 +..+z + 1 = 0 has been considered for its own sake, but it also serves as a specimen of a class of equations solvable by radicals, considered by Abel (1828), and since called Abelian equations, viz., for the Abelian equation of the order π, if x be any root, the roots are z, Ox, θ 2 x,. . . 0 n ~ 1 x (Ox being a rational function of x, and θ n x = x) ; the theory is, in fact, very analogous to that of the above particular case. A more general theorem obtained by Abel is as follows :—If the roots of an equation of any order are connected together in such wise that all the roots can be expressed rationally in terms of any one of them, say x ; if, moreover, Ox, θ- l x being any two of the roots, we have θθ- l x = 0 λ θx, the equation will be solvable algebraically. It is proper to refer also to Abel’s definition of an irreducible equation: — an equation φx = 0, the coefficients of which are rational functions of a certain number of known quantities a, b, c . . , is called irreducible when it is impossible to express its roots by an equation of an inferior degree, the coefficients of which are also rational functions of a, b, c .. . (or, what is the same thing, when φx does not break up into factors which are rational functions of a, b, c. . ). Abel applied his theory to the equations which present themselves in the division of the elliptic functions, but not to the modular equations.

32. But the theory of the algebraical solution of equations in its most complete form was established by Galois (born October 1811, killed in a duel May 1832; see his collected works, Lionville, t. xl., 1846). The definition of an irreducible equation resembles Abel’s,—an equation is reducible when it admits of a rational divisor, irreducible in the contrary case; only the word rational is used in this extended sense that, in connexion with the coefficients of the given equation, or with the irrational quantities (if any) whereof these are composed, he considers any number of other irrational quantities called “adjoint radicals,” and he terms rational any rational function of the coefficients (or the irrationals whereof they are composed) and of these adjoint radicals; the epithet irreducible is thus taken either absolutely or in a relative sense, according to the system of adjoint radicals which are taken into account. For instance, the equation z 4 + x i + x 2 + x + 1 = 0; the left hand side has here no rational divisor, and the equation is irreducible; but this function is = (x 2 + ⅛x + 1 ) 2 - ∣z 2 , and it has thus the irrational divisors z 2 + -l(1 + J5 y )x+ 1, <r 2 +£(1 —√5)z+1; and these, if we adjoin the radical x ∕5, are rational, and the equation is no longeι∙ irreducible. In the case of a given equation, assumed to be irreducible, the problem to solve the equation is, in fact, that of finding radicals by the adjunction of which the equation becomes reducible; for instance, the general quadric equation x 2 + px + q = 0 is irreducible, but it becomes reducible, breaking up into rational linear factors, when we adjoin the radical x ∕{p 2 - g. 1 ∙

The fundamental theorem is the Proposition I. of the “Mémoire sur les conditions de résolubilite des équations par radicaux;” viz., given an equation of which a, b, e . . are the m roots, there is always a group of permutations of the letters a, b, c . . possessed of the following properties :—

1. Every function of the roots invariable by the substitutions of the group is rationally known.

2. Reciprocally every rationally determinable function of the roots is invariable by the substitutions of the group.

Here by an invariable function is meant not only a function of which the form is invariable by the substitutions of the group, but further, one of which the value is invariable by these substitutions; for instance, if the equation be φx = 0, then φx is a function of the roots invariable by any substitution whatever. And in saying that a function is rationally known, it is meant that its value is expressible rationally in terms of the coefficients and of the adjoint quantities.

For instance, in the case of a general equation, the group is simply the system of the 1.2.3 . .. n permutations of all the roots, since, in this case, the only rationally determinable functions are the symmetric functions of the roots.

In the case of the equation x η ~ 1 . . . + x + 1 = 0, n a prime number, a, b, c... h==r, r 9 , r 9 ^... r 9η ~.^, where g is a prime root of n, then the group is the cyclical group abc... h, be. .. ha, ... hab ... j, that is, in this particular case the number of the permutations of the group is equal to the order of the equation.

This notion of the group of the original equation, or of the group of the equation as varied by the adjunction of a series of radicals, seems to be the fundamental one in Galois’s theory. But the problem of solution by radicals, instead of being the sole object of the theory, appears as the [9:8:509] first link of a long chain of questions relating to the transformation and classification of irrationals.

Returning to the question of solution by radicals, it will be readily understood that by the adjunction of a radical the group may be diminished; for instance, in the case of the general cubic, where the group is that of the .six permutations, by the adjunction of the square root which enters into the solution, the group is reduced to abc, bca, cab; that is, it becomes possible to express rationally, in terms of the coefficients and of the adjoint square root, any function such as a 2 b + δ 2 c + c 2 <z which is not altered by thθ cyclical substitution a into b, b into c, c into a. And hence, to determine whether an equation of a given form is solvable by radicals, the course of investigation is to inquire whether, by the successive adjunction of radicals, it is possible to reduce the original group of the equation so as to make it ultimately consist of a single permutation.

The condition in order that an equation of a given prime order n may be solvable by radicals was in this way obtained —in the first instance in the form (scarcely intelligible without further explanation) that every function of the roots αr 1 , x. 2 ... x n , invariable by the substitutions x αk+b for x k , must be rationally known; and then in the equivalent form that the resolvent equation of the order 1.2. .n-2 must have a rational root. In particular, the condition in order that a quintic equation may be solvable is that Lagrange’s resolvent of the order 6 may have a rational factor, a result obtained from a direct investigation in a valuable memoir by E. Luther, Grelle, t. xxxiv. (1847).

Among other results demonstrated or announced by Galois may be mentioned those relating to the modular equations in the theory of elliptic functions; for the transformations of the orders 5, 7, 11, the modular equations of the orders 6, 8, 12 are depressible to the orders 5, 7, 11 respectively; but for the transformation, n a prime number greater than 11, the depression is impossible.

The general theory of Galois in regard to the solution of equations was completed, and some of the demonstrations supplied by Betti (1852). See also Serret’s Cours d , Algèbre supérieure, 2d ed., 1854; 4th ed. 1877-78, in course of publication.

33. Returning to quintic equations, Jerrard (1835) established the theorem that the general quintic equation is by the extraction of only square and cubic roots reducible to the form x i + ax + b = Q, or what is the same thing, to κr ’ + x-k b = 0. The actual reduction by means of Tschirnhausen’s theorem was effected by Hermite in connexion with his elliptic-function solution of the quintic equation (1858) in a very elegant manner. It was show n by Cockle and Harley (1858-59) in connexion with the Jerrardian form, and by Cayley (1861), that Lagrange’s resolvent equation of the sixth order can be replaced by a more simple sextic equation occupying a like place in the theory.

The theory of the modular equations, more particularly for the case n = 5, has been studied by Hermite, Kronecker, and Brioschi. In the case n = 5, the modular equation of the order 6 depends, as already mentioned, on an equation of the order 5; and conversely the general quintic equation may be made to depend upon this modular equation of the order 6; that is, assuming the solution of this modular equation, we can solve (not by radicals) the general quintic equation; this is Hermite’s solution of the general quintic equation by elliptic functions (1858); it is analogous to the before-mentioned trigonometrical solution of the cubic equation. The theory is reproduced and developed in Brioschi’s memoir, “lieber die Auflösung der Gleichungen vom fünften Grade,” Math. Annalen, t. xiii. (1877-78).

34. The great modern work, reproducing the theories of

Galois, and exhibiting the theory of algebraic equations as a whole, is Jordan’s Traité des Substitutions et des Equations Algébriques, Paris, 1870. The work is divided into four books—book i., preliminary, relating to the theory of congruences; book ii. is in two chapters, the first relating to substitutions in general, the second to substitutions defined analytically, and chiefly to linear substitutions; book iii. has fouι - chapters, the first discussing the principles of the general theory, the other three containing applications to algebra, geometry, and the theory of transcendents; lastly, book iv., divided into seven chapters, contains a determination of the general types of equations solvable by radicals, and a complete system of classification of these types. A glance through the index will show the vast extent which the theory has assumed, and the form of general conclusions arrived at; thus, in book iii., the algebraical applications comprise Abelian equations, equations of Galois; the geometrical ones comprise Hesse’s equation, Clebsch’s equations, lines on a quartic surface having a nodal line, singular points of Kummer’s surface, lines on a cubic surface, problems of contact; the applications to the theory of transcendents comprise circular functions, elliptic functions (including division and the modular equation), hyperelliptic functions, solution of equations by transcendents. And on this last subject, solution of equations by transcendents, we may quote the result,—“the solution of the general equation of an order superior to five cannot be made to depend upon that of the equations for the division of the circular or elliptic functions;” and again (but with a reference to a possible case of exception), “the general equation cannot be solved by aid of the equations which give the division of the hyperelliptic functions into an odd number of parts.” (a. ca.)
